# -*- coding: utf-8 -*-
"""Classification BreastCancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uT8PxiGUM9khj9_6sYr9QXc5Qnwyob4V
"""

# Importing necessary libraries
from __future__ import division
from google.colab import drive
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Mount Google Drive
drive.mount('/content/drive/')

# Reading the dataset
df = pd.read_csv("/content/drive/MyDrive/AI/Breast_Cancer.csv")

# Checking the first few rows of the dataset
df.head()

# Exploring the shape and basic info of the dataset
print(df.shape)
df.info()

# Checking for missing values
pd.isnull(df).sum()

# Performing one-hot encoding on categorical variables
df_encoded = pd.get_dummies(df)

# Creating a heatmap of the correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(df_encoded.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

plt.hist(df.Status, bins = 3)

# Splitting the dataset into features (X) and target variable (y)
X = df.drop('Status', axis=1)
y = df['Status']

plt.hist(df.Age, bins = 10)
plt.xlabel('Age')
plt.ylabel('Number of People')

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print('x_train: ', x_train.shape)
print('x_test: ', x_test.shape)
print('y_train: ', y_train.shape)
print('y_test: ', y_test.shape)

print('################### X_TRAİN ####################')
x_train.info()
print('################### X_TEST ####################')
x_test.info()
print('################### Y_TRAİN ####################')
y_train.info()
print('################### Y_TEST ####################')
y_test.info()

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=9)

# Replacing original X_train and X_test with encoded versions
X_train = X_train_encoded
X_test = X_test_encoded

# Performing one-hot encoding on categorical variables
X_train = pd.get_dummies(X_train)
X_test = pd.get_dummies(X_test)

# Check if the data contains 'T Stage' column
if 'T Stage' in X_train.columns:
    # Initialize the scaler
    scaler = StandardScaler()

    # Fit and transform the training data
    X_train_scaled = scaler.fit_transform(X_train)

    # Transform the testing data using the fitted scaler
    X_test_scaled = scaler.transform(X_test)

    # Initialize and fit the Random Forest classifier
    clf = RandomForestClassifier()
    clf.fit(X_train_scaled, y_train)

    # Make predictions
    y_pred = clf.predict(X_test_scaled)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy:", accuracy)
else:
    # Handle missing column
    print("Column 'T Stage' not found in DataFrame. Please check your data.")

from sklearn.metrics import accuracy_score

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate error rate
error_rate = 1 - accuracy
print("Error rate:", error_rate)